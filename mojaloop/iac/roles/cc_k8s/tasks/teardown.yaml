- name: Delete resources before infra teardown
  shell: |
    export KUBECONFIG={{ kubeconfig_location }}/kubeconfig
    # Patch argo applications to remove syncPolicy
    kubectl patch application -n  {{ fact_argo_merged_config.namespace }} root-deployer --type json --patch='[ { "op": "remove", "path": "/spec/syncPolicy/automated" } ]' || true
    for app in capi-post-config capi vault vault-post-config gitlab-pre netbird-pre zitadel-pre gitlab nexus monitoring; do
      kubectl patch application -n  {{ fact_argo_merged_config.namespace }} $app --type json --patch='[ { "op": "remove", "path": "/spec/syncPolicy/automated" } ]' || true
    done

    # Delete crossplane MRs
    kubectl delete awsroute53record -n {{ fact_gitlab_namespace }} ceph-objectstore-rgw --ignore-not-found=true

    # Clean Gitlab PVC
    for sts in redis-node gitlab-gitaly-default; do
      kubectl patch statefulset redis-node -n {{ fact_gitlab_namespace }} -p '{"metadata":{"finalizers":[]}}' --type=merge || true
    done
    for pvc in $(kubectl get pvc -n {{ fact_gitlab_namespace }} -o name); do
      kubectl patch "$pvc" -n {{ fact_gitlab_namespace }} -p '{"metadata":{"finalizers":null}}' --type=merge || true
      kubectl delete "$pvc" -n {{ fact_gitlab_namespace }} --ignore-not-found
    done

    # Clean Monitoring PVC
    kubectl delete Prometheus -n {{ fact_monitoring_namespace }} prom-kube-prometheus-prometheus --ignore-not-found=true
    monitoring_statefulsets=(
      central-monitoring-grafana-mimir-ingester
      central-monitoring-grafana-mimir-store-gateway
      control-center-loki-grafana-loki-ingester
      central-monitoring-grafana-mimir-alertmanager
      central-monitoring-grafana-mimir-compactor
      control-center-loki-grafana-loki-querier
      prometheus-prom-kube-prometheus-prometheus
    )
    for sts in "${monitoring_statefulsets[@]}"; do
      echo "Patching and deleting StatefulSet: $sts"
      kubectl patch statefulset "$sts" -n {{ fact_monitoring_namespace }} -p '{"metadata":{"finalizers":[]}}' --type=merge || true
      kubectl delete statefulset "$sts" -n {{ fact_monitoring_namespace }} --ignore-not-found=true
    done
    for pvc in $(kubectl get pvc -n {{ fact_monitoring_namespace }} -o name); do
      kubectl patch "$pvc" -n {{ fact_monitoring_namespace }} -p '{"metadata":{"finalizers":null}}' --type=merge || true
      kubectl delete "$pvc" -n {{ fact_monitoring_namespace }} --ignore-not-found
    done

    # Clean Nexus PVC
    kubectl delete deployment nexus -n nexus --ignore-not-found=true
    for pvc in $(kubectl get pvc -n nexus -o name); do
      kubectl patch "$pvc" -n nexus -p '{"metadata":{"finalizers":null}}' --type=merge || true
      kubectl delete "$pvc" -n nexus --ignore-not-found
    done

    # Vault
    kubectl patch statefulset vault -n {{ fact_vault_namespace }} -p '{"metadata":{"finalizers":[]}}' --type=merge || true
    kubectl delete statefulset vault -n {{ fact_vault_namespace }} --ignore-not-found=true
    for pvc in $(kubectl get pvc -n {{ fact_vault_namespace }} -o name); do
      kubectl patch "$pvc" -n {{ fact_vault_namespace }} -p '{"metadata":{"finalizers":null}}' --type=merge || true
      kubectl delete "$pvc" -n {{ fact_vault_namespace }} --ignore-not-found
    done
  args:
    executable: /bin/bash
  ignore_errors: true

- name: Tear down ceph cluster on cc before sc cluster removal
  ansible.builtin.shell: |
    export KUBECONFIG={{ kubeconfig_location }}/kubeconfig
    kubectl patch application -n {{ fact_argo_merged_config.namespace }} {{ fact_storage_namespace }} --type json --patch='[ { "op": "remove", "path": "/spec/syncPolicy/automated" } ]' || true
    kubectl config set-context --current --namespace {{ fact_storage_namespace }}
    kubectl -n {{ fact_storage_namespace }} scale deployment rook-ceph-operator --replicas=0
    kubectl -n {{ fact_storage_namespace }} scale deployment csi-cephfsplugin-provisioner --replicas=0
    kubectl -n {{ fact_storage_namespace }} scale deployment csi-rbdplugin-provisioner --replicas=0
    for CRD in $(kubectl get crd -n {{ fact_storage_namespace }} | awk '/ceph.rook.io/ {print $1}'); do kubectl get -n {{ fact_storage_namespace }} "$CRD" -o name | xargs -I {} kubectl patch -n {{ fact_storage_namespace }} {} --type merge -p '{"metadata":{"finalizers": []}}';done
    kubectl delete cephcluster {{ fact_storage_namespace }} --ignore-not-found=true -n {{ fact_storage_namespace }}
    kubectl -n {{ fact_storage_namespace }} delete daemonset csi-cephfsplugin
    kubectl -n {{ fact_storage_namespace }} delete daemonset csi-rbdplugin
  args:
    executable: /bin/bash
  ignore_errors: true

- name: Delete sc cluster before infra teardown
  shell: |
    export KUBECONFIG={{ kubeconfig_location }}/kubeconfig
    kubectl delete cluster.cluster.x-k8s.io -n {{ fact_capi_cluster_namespace }} {{ fact_capi_cluster_name }} --ignore-not-found=true
    sleep 60
  args:
    executable: /bin/bash
  ignore_errors: true
# - name: Pause to finish resources deletion
#   ansible.builtin.pause:
#     seconds: 300
# - name: Wait for vault to be gone
#   shell: |
#     export KUBECONFIG={{ kubeconfig_location }}/kubeconfig
#     kubectl patch workspace netbird-pre-config --type json --patch='[ { "op": "remove", "path": "/metadata/finalizers" } ]' || true
#     kubectl patch workspace zitadel-post-config --type json --patch='[ { "op": "remove", "path": "/metadata/finalizers" } ]' || true
#     kubectl patch workspace zitadel-argocd-oidc-config --type json --patch='[ { "op": "remove", "path": "/metadata/finalizers" } ]' || true
#     kubectl patch workspace zitadel-vault-oidc-config --type json --patch='[ { "op": "remove", "path": "/metadata/finalizers" } ]'  || true
#     export zitadel_pvcs=$(kubectl get pvcs -n zitadel --no-headers -o custom-columns=":metadata.name") || true
#     for n in $zitadel_pvcs; do kubectl patch -n zitadel pvc $n --type json --patch='[ { "op": "remove", "path": "/metadata/finalizers" } ]' ; done || true
#     kubectl patch workspace vault-post-config --type json --patch='[ { "op": "remove", "path": "/metadata/finalizers" } ]' || true
#     kubectl --kubeconfig {{ kubeconfig_location }}/kubeconfig get application -n {{ fact_argo_merged_config.namespace }} vault
#   register: outputapp
#   until: outputapp is failed
#   retries: 100
#   delay: 30
#   ignore_errors: true

# - name: Sleep for 300 seconds and continue with play
#   ansible.builtin.wait_for:
#     timeout: 300